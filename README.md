

# Audio/Video to Sign Language Conversion Tool

## Overview
This project aims to create an audio/video to sign language conversion tool using a Convolutional Neural Network (CNN) + Gated Recurrent Unit (GRU) model. The system enables real-time recognition of continuous American Sign Language (ASL) gestures, enhancing accessibility for the deaf and hard of hearing community.

## Features
- Real-time recognition of continuous ASL gestures from audio/video input.
- Integration of CNN and GRU model for accurate sign language recognition.
- Deployment of sign segmentation algorithms to improve system robustness and adaptability to various environments and user preferences.
- Integration with ChatGPT for seamless interactive communication.

## Installation
1. Clone this repository to your local machine.
2. Install the required dependencies by running `pip install -r requirements.txt`.
3. Download pre-trained models for CNN, GRU, and ChatGPT.
4. Set up any additional environment configurations as needed.

## Usage
1. Run the main script `test.py`.
2. Provide audio/video input containing ASL gestures.
3. The tool will process the input and provide real-time recognition of ASL gestures.
4. Explore different functionalities and options as needed.

## Contributing
Contributions to this project are welcome! Please fork the repository, make your changes, and submit a pull request with a brief description of your modifications.

## License
This project is licensed under the [MIT License](LICENSE).

---

